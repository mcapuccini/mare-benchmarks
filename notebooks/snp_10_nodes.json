{"paragraphs":[{"text":"%spark.dep\n// Download deps\nz.load(\"org.bdgenomics.adam:adam-core-spark2_2.11:0.29.0\")\nz.addRepo(\"sonatype\").url(\"https://oss.sonatype.org/content/repositories/snapshots/\").snapshot\nz.load(\"se.uu.it:mare:0.4.0-SNAPSHOT\")","user":"anonymous","dateUpdated":"2019-12-18T08:51:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@260861ec\n"}]},"apps":[],"jobName":"paragraph_1576573915479_515755427","id":"20191115-152721_1673536908","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:51:55+0000","dateFinished":"2019-12-18T08:52:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6600"},{"text":"// Check Spark version\nsc.version","user":"anonymous","dateUpdated":"2019-12-18T08:51:56+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res5: String = 2.3.2\n"}]},"apps":[],"jobName":"paragraph_1576573915489_708217096","id":"20191115-152002_466578857","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:52:00+0000","dateFinished":"2019-12-18T08:52:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6601"},{"text":"// Imports\nimport org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._","user":"anonymous","dateUpdated":"2019-12-18T08:51:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._\n"}]},"apps":[],"jobName":"paragraph_1576573915490_1529898087","id":"20191121-133156_650750325","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:52:06+0000","dateFinished":"2019-12-18T08:52:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6602"},{"text":"val nodes = 10","user":"anonymous","dateUpdated":"2019-12-18T08:52:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"nodes: Int = 10\n"}]},"apps":[],"jobName":"paragraph_1576573915490_-586647751","id":"20191204-134523_1628230396","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:52:15+0000","dateFinished":"2019-12-18T08:52:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6603"},{"text":"// Read and interlace data\nval fr = sc.newAPIHadoopFile(\n    \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_1*\",\n    classOf[SingleFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\nval rr = sc.newAPIHadoopFile(\n        \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_2*\",\n        classOf[SingleFastqInputFormat],\n        classOf[Void],\n        classOf[Text]\n).map(_._2.toString)\nval data = fr.zip(rr).map { \n    case(fr,rr) => fr+rr.dropRight(1) // Interlace\n}","user":"anonymous","dateUpdated":"2019-12-17T09:34:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576573915491_1026778322","id":"20191121-133240_2075256714","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-17T09:34:48+0000","dateFinished":"2019-12-17T09:34:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6604"},{"text":"// Ingest data in HDFS\ndata.repartition(nodes).saveAsTextFile(\"hdfs://spark-cluster-master-000/HG02666\")","user":"anonymous","dateUpdated":"2019-12-17T09:34:55+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1576573915492_-1833498225","id":"20191122-145147_597312852","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-17T09:34:56+0000","dateFinished":"2019-12-17T09:38:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6605"},{"text":"%sh\n# Remove empty extra file\nhadoop fs -rm -r hdfs://spark-cluster-master-000/HG02666/_SUCCESS","user":"anonymous","dateUpdated":"2019-12-17T09:42:37+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576573915492_-944916204","id":"20191125-125048_478756895","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-17T09:42:38+0000","dateFinished":"2019-12-17T09:42:40+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6606"},{"text":"// Full pipeline (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// SNP pipeline\nval res = new MaRe(fastq).map(\n    inputMountPoint = TextFile(\"/chunk.fastq\"),\n    outputMountPoint = TextFile(\"/aln.sam\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        reference_genome=/ref/human_g1k_v37.fasta\n        reads=/chunk.fastq\n        bwa mem -t 8 -p $reference_genome $reads | samtools view > /aln.sam\n        \"\"\"\n).repartitionBy(\n    keyBy = (aln: String) => {\n        val chrStr = aln.split(\"\\\\s+\")(2)\n        if(chrStr.forall(Character.isDigit)) {\n            chrStr.toInt\n        } else {\n            chrStr match {\n                case \"X\" => 23\n                case \"Y\" => 24\n                case \"MT\" => 25\n                case _ => chrStr.hashCode\n            }\n        }\n    },\n    numPartitions = nodes\n).map(\n    inputMountPoint = TextFile(\"/aln.sam\"),\n    outputMountPoint = BinaryFiles(\"/results\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        cat /ref/human_g1k_v37.dict /aln.sam > /aln.header.sam\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        gatk AddOrReplaceReadGroups --INPUT=/aln.header.sam \\\n            --OUTPUT=/aln.header.sorted.rg.bam \\\n            --SORT_ORDER=coordinate --RGID=HG02666-id \\\n            --RGLB=HG02666-lib \\\n            --RGPL=ILLUMINA \\\n            --RGPU=HG02666-01 \\\n            --RGSM=HG02666\n        gatk BuildBamIndex --INPUT=/aln.header.sorted.rg.bam\n        \n        reference_genome=/ref/human_g1k_v37.fasta\n        gatk HaplotypeCaller --native-pair-hmm-threads 8 -R $reference_genome -I /aln.header.sorted.rg.bam -O /results/aln.${UUID}.g.vcf\n        gzip /results/*\n        \"\"\"\n).reduce(\n    inputMountPoint = BinaryFiles(\"/in\"),\n    outputMountPoint = BinaryFiles(\"/out\"),\n    imageName = \"opengenomics/vcftools-tools:latest\",\n    command =\n        \"\"\"\n        set -e\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        vcf-concat /in/*.vcf.gz | gzip -c > /out/results.${UUID}.g.vcf.gz\n        \"\"\"\n).rdd.saveAsObjectFile(\"hdfs://spark-cluster-master-000/out\")\n// Took 4 hrs 14 min 48 sec.\n// BWA 49 min","user":"anonymous","dateUpdated":"2019-12-18T08:51:38+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:40\n"}]},"apps":[],"jobName":"paragraph_1576573915493_1636882413","id":"20191122-150732_14273216","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-17T16:36:49+0000","dateFinished":"2019-12-17T20:51:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6607"},{"text":"// Define pipePartitions\nimport org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\n\ndef pipePartitions(rdd: RDD[String], command: Seq[String]) = {\n    rdd.mapPartitions { it =>\n        //Start executable\n        val pb = new ProcessBuilder(command.asJava)\n        val proc = pb.start\n    \n        // Start a thread to print the process's stderr to ours\n        new Thread(\"stderr reader\") {\n            override def run() {\n                for (line <- Source.fromInputStream(proc.getErrorStream).getLines) {\n                    System.err.println(line)\n                }\n            }\n        }.start\n    \n        // Start a thread to feed the process input \n        new Thread(\"stdin writer\") {\n            override def run() {\n                val out = new PrintWriter(proc.getOutputStream)\n                it.foreach { record =>\n                    out.print(record)\n                }\n                out.close()   \n            }\n        }.start\n        \n        //Return processed partition\n        Source.fromInputStream(proc.getInputStream).getLines()\n    }\n}","user":"anonymous","dateUpdated":"2019-12-18T08:52:23+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\npipePartitions: (rdd: org.apache.spark.rdd.RDD[String], command: Seq[String])org.apache.spark.rdd.RDD[String]\n"}]},"apps":[],"jobName":"paragraph_1576573915493_-1492983235","id":"20191205-114334_1532054385","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:52:24+0000","dateFinished":"2019-12-18T08:52:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6608"},{"text":"// Bwa with RDD pipe (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// Bwa\nval sam = pipePartitions(\n    fastq,\n    Seq(\"docker\", \"run\", \"-i\", \"mcapuccini/alignment:latest\", \"sh\", \"-c\", \n        \"bwa mem -t 8 -p /ref/human_g1k_v37.fasta - | samtools view\"\n    )\n)\n\n// Partition by\nval partSam = sam.keyBy { aln =>\n    val chrStr = aln.split(\"\\\\s+\")(2)\n    if(chrStr.forall(Character.isDigit)) {\n        chrStr.toInt\n    } else {\n        chrStr match {\n            case \"X\" => 23\n            case \"Y\" => 24\n            case \"MT\" => 25\n            case _ => chrStr.hashCode\n        }\n    }\n}.partitionBy(new org.apache.spark.HashPartitioner(nodes)).map(_._2)\n\n// Save\npartSam.saveAsTextFile(\"hdfs://spark-cluster-master-000/out_pipe\")\n// Took 43 min 19 sec.","user":"anonymous","dateUpdated":"2019-12-18T09:37:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:44\nsam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at mapPartitions at <console>:36\npartSam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at map at <console>:58\n"}]},"apps":[],"jobName":"paragraph_1576573915494_1960820169","id":"20191204-160505_1543275415","dateCreated":"2019-12-17T09:11:55+0000","dateStarted":"2019-12-18T08:52:35+0000","dateFinished":"2019-12-18T09:35:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6609"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576659154627_992447810","id":"20191218-085234_84524845","dateCreated":"2019-12-18T08:52:34+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:6610"}],"name":"snp_10_nodes","id":"2EY3T3XTK","noteParams":{},"noteForms":{},"angularObjects":{"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}