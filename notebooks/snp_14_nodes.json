{"paragraphs":[{"text":"%spark.dep\n// Download deps\nz.load(\"org.bdgenomics.adam:adam-core-spark2_2.11:0.29.0\")\nz.addRepo(\"sonatype\").url(\"https://oss.sonatype.org/content/repositories/snapshots/\").snapshot\nz.load(\"se.uu.it:mare:0.4.0-SNAPSHOT\")","user":"anonymous","dateUpdated":"2019-12-16T08:57:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@1858f274\n"}]},"apps":[],"jobName":"paragraph_1573831641525_-1412127217","id":"20191115-152721_1673536908","dateCreated":"2019-11-15T15:27:21+0000","dateStarted":"2019-12-16T08:57:31+0000","dateFinished":"2019-12-16T08:57:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10576"},{"text":"// Check Spark version\nsc.version","user":"anonymous","dateUpdated":"2019-12-16T08:58:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res11: String = 2.3.2\n"}]},"apps":[],"jobName":"paragraph_1573831202878_-225584474","id":"20191115-152002_466578857","dateCreated":"2019-11-15T15:20:02+0000","dateStarted":"2019-12-16T08:58:09+0000","dateFinished":"2019-12-16T08:58:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10577"},{"text":"// Imports\nimport org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._","user":"anonymous","dateUpdated":"2019-12-16T08:58:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._\n"}]},"apps":[],"jobName":"paragraph_1574343116836_581892589","id":"20191121-133156_650750325","dateCreated":"2019-11-21T13:31:56+0000","dateStarted":"2019-12-16T08:58:11+0000","dateFinished":"2019-12-16T08:58:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10578"},{"text":"val nodes = 14","user":"anonymous","dateUpdated":"2019-12-16T08:58:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"nodes: Int = 14\n"}]},"apps":[],"jobName":"paragraph_1575467123049_901656277","id":"20191204-134523_1628230396","dateCreated":"2019-12-04T13:45:23+0000","dateStarted":"2019-12-16T08:58:14+0000","dateFinished":"2019-12-16T08:58:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10579"},{"text":"// Read and interlace data\nval fr = sc.newAPIHadoopFile(\n    \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_1*\",\n    classOf[SingleFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\nval rr = sc.newAPIHadoopFile(\n        \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_2*\",\n        classOf[SingleFastqInputFormat],\n        classOf[Void],\n        classOf[Text]\n).map(_._2.toString)\nval data = fr.zip(rr).map { \n    case(fr,rr) => fr+rr.dropRight(1) // Interlace\n}","user":"anonymous","dateUpdated":"2019-12-16T08:58:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fr: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:46\nrr: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at map at <console>:45\ndata: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at map at <console>:44\n"}]},"apps":[],"jobName":"paragraph_1574343160427_-307187652","id":"20191121-133240_2075256714","dateCreated":"2019-11-21T13:32:40+0000","dateStarted":"2019-12-16T08:58:21+0000","dateFinished":"2019-12-16T08:58:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10580"},{"text":"// Ingest data in HDFS\ndata.repartition(nodes).saveAsTextFile(\"hdfs://spark-cluster-master-000/HG02666\")","user":"anonymous","dateUpdated":"2019-12-15T17:28:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1574434307077_175348134","id":"20191122-145147_597312852","dateCreated":"2019-11-22T14:51:47+0000","dateStarted":"2019-12-15T17:28:40+0000","dateFinished":"2019-12-15T17:33:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10581"},{"text":"%sh\n# Remove empty extra file\nhadoop fs -rm -r hdfs://spark-cluster-master-000/HG02666/_SUCCESS","user":"anonymous","dateUpdated":"2019-12-15T21:04:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2019-12-15 21:04:27,464 INFO  [main] fs.TrashPolicyDefault (TrashPolicyDefault.java:initialize(92)) - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\nDeleted hdfs://spark-cluster-master-000/HG02666/_SUCCESS\n"}]},"apps":[],"jobName":"paragraph_1574686248536_1122006768","id":"20191125-125048_478756895","dateCreated":"2019-11-25T12:50:48+0000","dateStarted":"2019-12-15T21:04:24+0000","dateFinished":"2019-12-15T21:04:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10582"},{"text":"// Full pipeline (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// SNP pipeline\nval res = new MaRe(fastq).map(\n    inputMountPoint = TextFile(\"/chunk.fastq\"),\n    outputMountPoint = TextFile(\"/aln.sam\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        reference_genome=/ref/human_g1k_v37.fasta\n        reads=/chunk.fastq\n        bwa mem -t 8 -p $reference_genome $reads | samtools view > /aln.sam\n        \"\"\"\n).repartitionBy(\n    keyBy = (aln: String) => {\n        val chrStr = aln.split(\"\\\\s+\")(2)\n        if(chrStr.forall(Character.isDigit)) {\n            chrStr.toInt\n        } else {\n            chrStr match {\n                case \"X\" => 23\n                case \"Y\" => 24\n                case \"MT\" => 25\n                case _ => chrStr.hashCode\n            }\n        }\n    },\n    numPartitions = nodes\n).map(\n    inputMountPoint = TextFile(\"/aln.sam\"),\n    outputMountPoint = BinaryFiles(\"/results\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        cat /ref/human_g1k_v37.dict /aln.sam > /aln.header.sam\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        gatk AddOrReplaceReadGroups --INPUT=/aln.header.sam \\\n            --OUTPUT=/aln.header.sorted.rg.bam \\\n            --SORT_ORDER=coordinate --RGID=HG02666-id \\\n            --RGLB=HG02666-lib \\\n            --RGPL=ILLUMINA \\\n            --RGPU=HG02666-01 \\\n            --RGSM=HG02666\n        gatk BuildBamIndex --INPUT=/aln.header.sorted.rg.bam\n        \n        reference_genome=/ref/human_g1k_v37.fasta\n        gatk HaplotypeCaller --native-pair-hmm-threads 8 -R $reference_genome -I /aln.header.sorted.rg.bam -O /results/aln.${UUID}.g.vcf\n        gzip /results/*\n        \"\"\"\n).reduce(\n    inputMountPoint = BinaryFiles(\"/in\"),\n    outputMountPoint = BinaryFiles(\"/out\"),\n    imageName = \"opengenomics/vcftools-tools:latest\",\n    command =\n        \"\"\"\n        set -e\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        vcf-concat /in/*.vcf.gz | gzip -c > /out/results.${UUID}.g.vcf.gz\n        \"\"\"\n).rdd.saveAsObjectFile(\"hdfs://spark-cluster-master-000/out\")\n// Took 3 hrs 24 min 10 sec\n// BWA 36 min","user":"anonymous","dateUpdated":"2019-12-17T08:09:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[7] at map at <console>:47\n"}]},"apps":[],"jobName":"paragraph_1574435252288_-583243488","id":"20191122-150732_14273216","dateCreated":"2019-11-22T15:07:32+0000","dateStarted":"2019-12-16T08:58:43+0000","dateFinished":"2019-12-16T12:22:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10583"},{"text":"// Define pipePartitions\nimport org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\n\ndef pipePartitions(rdd: RDD[String], command: Seq[String]) = {\n    rdd.mapPartitions { it =>\n        //Start executable\n        val pb = new ProcessBuilder(command.asJava)\n        val proc = pb.start\n    \n        // Start a thread to print the process's stderr to ours\n        new Thread(\"stderr reader\") {\n            override def run() {\n                for (line <- Source.fromInputStream(proc.getErrorStream).getLines) {\n                    System.err.println(line)\n                }\n            }\n        }.start\n    \n        // Start a thread to feed the process input \n        new Thread(\"stdin writer\") {\n            override def run() {\n                val out = new PrintWriter(proc.getOutputStream)\n                it.foreach { record =>\n                    out.print(record)\n                }\n                out.close()   \n            }\n        }.start\n        \n        //Return processed partition\n        Source.fromInputStream(proc.getInputStream).getLines()\n    }\n}","user":"anonymous","dateUpdated":"2019-12-12T15:41:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\npipePartitions: (rdd: org.apache.spark.rdd.RDD[String], command: Seq[String])org.apache.spark.rdd.RDD[String]\n"}]},"apps":[],"jobName":"paragraph_1575546214521_-1414608937","id":"20191205-114334_1532054385","dateCreated":"2019-12-05T11:43:34+0000","dateStarted":"2019-12-12T15:41:18+0000","dateFinished":"2019-12-12T15:41:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10584"},{"text":"// Bwa with RDD pipe (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// Bwa\nval sam = pipePartitions(\n    fastq,\n    Seq(\"docker\", \"run\", \"-i\", \"mcapuccini/alignment:latest\", \"sh\", \"-c\", \n        \"bwa mem -t 8 -p /ref/human_g1k_v37.fasta - | samtools view\"\n    )\n)\n\n// Partition by\nval partSam = sam.keyBy { aln =>\n    val chrStr = aln.split(\"\\\\s+\")(2)\n    if(chrStr.forall(Character.isDigit)) {\n        chrStr.toInt\n    } else {\n        chrStr match {\n            case \"X\" => 23\n            case \"Y\" => 24\n            case \"MT\" => 25\n            case _ => chrStr.hashCode\n        }\n    }\n}.partitionBy(new org.apache.spark.HashPartitioner(nodes)).map(_._2)\n\n// Save\npartSam.saveAsTextFile(\"hdfs://spark-cluster-master-000/out_pipe\")\n// Took 30 min 1 sec","user":"anonymous","dateUpdated":"2019-12-16T08:58:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:44\nsam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at mapPartitions at <console>:36\npartSam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at map at <console>:58\n"}]},"apps":[],"jobName":"paragraph_1575475505721_-612657823","id":"20191204-160505_1543275415","dateCreated":"2019-12-04T16:05:05+0000","dateStarted":"2019-12-12T15:41:34+0000","dateFinished":"2019-12-12T16:11:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10585"}],"name":"snp_14_nodes","id":"2ESMJAHB4","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}