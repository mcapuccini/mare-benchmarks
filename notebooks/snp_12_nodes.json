{"paragraphs":[{"text":"%spark.dep\n// Download deps\nz.load(\"org.bdgenomics.adam:adam-core-spark2_2.11:0.29.0\")\nz.addRepo(\"sonatype\").url(\"https://oss.sonatype.org/content/repositories/snapshots/\").snapshot\nz.load(\"se.uu.it:mare:0.4.0-SNAPSHOT\")","user":"anonymous","dateUpdated":"2019-12-17T08:10:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@260861ec\n"}]},"apps":[],"jobName":"paragraph_1576504412906_-771553124","id":"20191115-152721_1673536908","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:01+0000","dateFinished":"2019-12-17T08:10:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8575"},{"text":"// Check Spark version\nsc.version","user":"anonymous","dateUpdated":"2019-12-17T08:10:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res5: String = 2.3.2\n"}]},"apps":[],"jobName":"paragraph_1576504412913_1714138106","id":"20191115-152002_466578857","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:05+0000","dateFinished":"2019-12-17T08:10:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8576"},{"text":"// Imports\nimport org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._","user":"anonymous","dateUpdated":"2019-12-17T08:10:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.bdgenomics.adam.io._\nimport org.apache.hadoop.io.Text\nimport se.uu.it.mare._\n"}]},"apps":[],"jobName":"paragraph_1576504412913_-685677885","id":"20191121-133156_650750325","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:13+0000","dateFinished":"2019-12-17T08:10:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8577"},{"text":"val nodes = 12","user":"anonymous","dateUpdated":"2019-12-17T08:10:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"nodes: Int = 12\n"}]},"apps":[],"jobName":"paragraph_1576504412914_1652369986","id":"20191204-134523_1628230396","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:21+0000","dateFinished":"2019-12-17T08:10:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8578"},{"text":"// Read and interlace data\nval fr = sc.newAPIHadoopFile(\n    \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_1*\",\n    classOf[SingleFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\nval rr = sc.newAPIHadoopFile(\n        \"s3n://1000genomes/phase3/data/HG02666/sequence_read/*_2*\",\n        classOf[SingleFastqInputFormat],\n        classOf[Void],\n        classOf[Text]\n).map(_._2.toString)\nval data = fr.zip(rr).map { \n    case(fr,rr) => fr+rr.dropRight(1) // Interlace\n}","user":"anonymous","dateUpdated":"2019-12-16T14:09:14+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fr: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[7] at map at <console>:39\nrr: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[9] at map at <console>:38\ndata: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[11] at map at <console>:37\n"}]},"apps":[],"jobName":"paragraph_1576504412914_-2073331786","id":"20191121-133240_2075256714","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-16T14:09:15+0000","dateFinished":"2019-12-16T14:09:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8579"},{"text":"// Ingest data in HDFS\ndata.repartition(nodes).saveAsTextFile(\"hdfs://spark-cluster-master-000/HG02666\")","user":"anonymous","dateUpdated":"2019-12-16T14:09:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1576504412915_1398328172","id":"20191122-145147_597312852","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-16T14:09:20+0000","dateFinished":"2019-12-16T14:15:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8580"},{"text":"%sh\n# Remove empty extra file\nhadoop fs -rm -r hdfs://spark-cluster-master-000/HG02666/_SUCCESS","user":"anonymous","dateUpdated":"2019-12-16T14:23:05+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2019-12-16 14:23:08,240 INFO  [main] fs.TrashPolicyDefault (TrashPolicyDefault.java:initialize(92)) - Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\nDeleted hdfs://spark-cluster-master-000/HG02666/_SUCCESS\n"}]},"apps":[],"jobName":"paragraph_1576504412915_-1607717739","id":"20191125-125048_478756895","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-16T14:23:06+0000","dateFinished":"2019-12-16T14:23:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8581"},{"text":"// Full pipeline (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// SNP pipeline\nval res = new MaRe(fastq).map(\n    inputMountPoint = TextFile(\"/chunk.fastq\"),\n    outputMountPoint = TextFile(\"/aln.sam\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        reference_genome=/ref/human_g1k_v37.fasta\n        reads=/chunk.fastq\n        bwa mem -t 8 -p $reference_genome $reads | samtools view > /aln.sam\n        \"\"\"\n).repartitionBy(\n    keyBy = (aln: String) => {\n        val chrStr = aln.split(\"\\\\s+\")(2)\n        if(chrStr.forall(Character.isDigit)) {\n            chrStr.toInt\n        } else {\n            chrStr match {\n                case \"X\" => 23\n                case \"Y\" => 24\n                case \"MT\" => 25\n                case _ => chrStr.hashCode\n            }\n        }\n    },\n    numPartitions = nodes\n).map(\n    inputMountPoint = TextFile(\"/aln.sam\"),\n    outputMountPoint = BinaryFiles(\"/results\"),\n    imageName = \"mcapuccini/alignment:latest\",\n    command =\n        \"\"\"\n        set -e\n        cat /ref/human_g1k_v37.dict /aln.sam > /aln.header.sam\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        gatk AddOrReplaceReadGroups --INPUT=/aln.header.sam \\\n            --OUTPUT=/aln.header.sorted.rg.bam \\\n            --SORT_ORDER=coordinate --RGID=HG02666-id \\\n            --RGLB=HG02666-lib \\\n            --RGPL=ILLUMINA \\\n            --RGPU=HG02666-01 \\\n            --RGSM=HG02666\n        gatk BuildBamIndex --INPUT=/aln.header.sorted.rg.bam\n        \n        reference_genome=/ref/human_g1k_v37.fasta\n        gatk HaplotypeCaller --native-pair-hmm-threads 8 -R $reference_genome -I /aln.header.sorted.rg.bam -O /results/aln.${UUID}.g.vcf\n        gzip /results/*\n        \"\"\"\n).reduce(\n    inputMountPoint = BinaryFiles(\"/in\"),\n    outputMountPoint = BinaryFiles(\"/out\"),\n    imageName = \"opengenomics/vcftools-tools:latest\",\n    command =\n        \"\"\"\n        set -e\n        UUID=$(cat /proc/sys/kernel/random/uuid)\n        vcf-concat /in/*.vcf.gz | gzip -c > /out/results.${UUID}.g.vcf.gz\n        \"\"\"\n).rdd.saveAsObjectFile(\"hdfs://spark-cluster-master-000/out\")\n// Took 3 hrs 27 min 27 sec\n// BWA 43 min","user":"anonymous","dateUpdated":"2019-12-17T08:08:16+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:40\n"}]},"apps":[],"jobName":"paragraph_1576504412916_1998295193","id":"20191122-150732_14273216","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-16T14:24:23+0000","dateFinished":"2019-12-16T17:51:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8582"},{"text":"// Define pipePartitions\nimport org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\n\ndef pipePartitions(rdd: RDD[String], command: Seq[String]) = {\n    rdd.mapPartitions { it =>\n        //Start executable\n        val pb = new ProcessBuilder(command.asJava)\n        val proc = pb.start\n    \n        // Start a thread to print the process's stderr to ours\n        new Thread(\"stderr reader\") {\n            override def run() {\n                for (line <- Source.fromInputStream(proc.getErrorStream).getLines) {\n                    System.err.println(line)\n                }\n            }\n        }.start\n    \n        // Start a thread to feed the process input \n        new Thread(\"stdin writer\") {\n            override def run() {\n                val out = new PrintWriter(proc.getOutputStream)\n                it.foreach { record =>\n                    out.print(record)\n                }\n                out.close()   \n            }\n        }.start\n        \n        //Return processed partition\n        Source.fromInputStream(proc.getInputStream).getLines()\n    }\n}","user":"anonymous","dateUpdated":"2019-12-17T08:10:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport scala.collection.JavaConverters.seqAsJavaListConverter\nimport scala.io.Source\nimport java.io.PrintWriter\npipePartitions: (rdd: org.apache.spark.rdd.RDD[String], command: Seq[String])org.apache.spark.rdd.RDD[String]\n"}]},"apps":[],"jobName":"paragraph_1576504412916_57056348","id":"20191205-114334_1532054385","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:44+0000","dateFinished":"2019-12-17T08:10:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8583"},{"text":"// Bwa with RDD pipe (restart interpeter, docker containers already in nodes)\n\n// Read interleaved data\nval fastq = sc.newAPIHadoopFile(\n    \"hdfs://spark-cluster-master-000/HG02666\",\n    classOf[InterleavedFastqInputFormat],\n    classOf[Void],\n    classOf[Text]\n).map(_._2.toString)\n\n// Bwa\nval sam = pipePartitions(\n    fastq,\n    Seq(\"docker\", \"run\", \"-i\", \"mcapuccini/alignment:latest\", \"sh\", \"-c\", \n        \"bwa mem -t 8 -p /ref/human_g1k_v37.fasta - | samtools view\"\n    )\n)\n\n// Partition by\nval partSam = sam.keyBy { aln =>\n    val chrStr = aln.split(\"\\\\s+\")(2)\n    if(chrStr.forall(Character.isDigit)) {\n        chrStr.toInt\n    } else {\n        chrStr match {\n            case \"X\" => 23\n            case \"Y\" => 24\n            case \"MT\" => 25\n            case _ => chrStr.hashCode\n        }\n    }\n}.partitionBy(new org.apache.spark.HashPartitioner(nodes)).map(_._2)\n\n// Save\npartSam.saveAsTextFile(\"hdfs://spark-cluster-master-000/out_pipe\")\n// Took 37 min 59 sec","user":"anonymous","dateUpdated":"2019-12-17T08:50:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"fastq: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:44\nsam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at mapPartitions at <console>:36\npartSam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at map at <console>:58\n"}]},"apps":[],"jobName":"paragraph_1576504412917_-1506545084","id":"20191204-160505_1543275415","dateCreated":"2019-12-16T13:53:32+0000","dateStarted":"2019-12-17T08:10:50+0000","dateFinished":"2019-12-17T08:48:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8584"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576570250217_386841940","id":"20191217-081050_595494122","dateCreated":"2019-12-17T08:10:50+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:8585"}],"name":"snp_12_nodes","id":"2EX7TVV9B","noteParams":{},"noteForms":{},"angularObjects":{"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}